# ğŸ›’ Proyecto: ReplicaciÃ³n Primario-Secundario MongoDB con Dataset Brazilian E-commerce

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema completo de **replicaciÃ³n Primario-Secundario en MongoDB** utilizando el dataset de **Brazilian E-commerce de Kaggle**. El proyecto incluye:

- **AnÃ¡lisis Exploratorio de Datos (EDA)** completo
- **Proceso ETL** con limpieza inteligente de datos
- **ReplicaciÃ³n MongoDB** con Docker (1 primario + 2 secundarios)
- **15 consultas CRUD** complejas con agregaciones
- **VerificaciÃ³n de replicaciÃ³n** entre nodos

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MongoDB       â”‚    â”‚   MongoDB       â”‚    â”‚   MongoDB       â”‚
â”‚   Primary       â”‚â—„â”€â”€â–ºâ”‚   Secondary 1   â”‚â—„â”€â”€â–ºâ”‚   Secondary 2   â”‚
â”‚   (Port 27017)  â”‚    â”‚   (Port 27018)  â”‚    â”‚   (Port 27019)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Jupyter       â”‚
                    â”‚   Notebooks     â”‚
                    â”‚   (EDA + CRUD)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ CaracterÃ­sticas del Proyecto

- **ReplicaciÃ³n MongoDB**: ConfiguraciÃ³n automÃ¡tica de replica set con 1 primario y 2 secundarios
- **Dataset Real**: Dataset de e-commerce brasileÃ±o con 9 archivos CSV interrelacionados
- **AnÃ¡lisis Completo**: EDA detallado y proceso ETL robusto
- **15 Consultas CRUD**: Operaciones complejas de Create, Read, Update, Delete
- **Docker Compose**: ConfiguraciÃ³n automatizada del cluster
- **Jupyter Notebooks**: AnÃ¡lisis interactivo y documentado
- **Scripts de AutomatizaciÃ³n**: Setup y inicio automÃ¡tico del proyecto
- **Barras de Progreso**: Interfaz visual con tqdm y colores para mejor experiencia de usuario
- **Utilidades de Progreso**: MÃ³dulo dedicado para mostrar progreso en notebooks

## ğŸš€ ConfiguraciÃ³n Inicial

### 1. Prerrequisitos

- **Python 3.8+**
- **Docker y Docker Compose**
- **Git**
- **Anaconda o Miniconda** (recomendado)

### 2. Clonar el Repositorio

```bash
git clone <URL_DEL_REPOSITORIO>
cd MongoDB_Replicacion_Proyecto
```

### 3. Configurar Entorno Conda

```bash
# Crear entorno conda
conda create -n mongo python=3.8 -y

# Activar entorno
conda activate mongo

# Verificar activaciÃ³n
conda info --envs
```

### 4. Instalar Dependencias

```bash
# Instalar librerÃ­as principales
pip install pandas numpy matplotlib seaborn pymongo kagglehub

# O instalar todas las dependencias de una vez
pip install -r requirements.txt
```

### 5. Configurar Kaggle (Opcional)

Si quieres usar tu propia cuenta de Kaggle:

```bash
# Crear archivo kaggle.json en data/
echo '{"username":"tu_usuario","key":"tu_api_key"}' > data/kaggle.json
```

## ğŸ“¦ Estructura del Proyecto

```
MongoDB_Replicacion_Proyecto/
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ kaggle.json                 # Credenciales Kaggle
â”‚   â””â”€â”€ ventas.json                 # Dataset (se descarga automÃ¡ticamente)
â”œâ”€â”€ ğŸ“ docker/
â”‚   â”œâ”€â”€ docker-compose.yml          # ConfiguraciÃ³n MongoDB replica set
â”‚   â””â”€â”€ initReplica.js              # Script inicializaciÃ³n replica set
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â”œâ”€â”€ EDA_ETL_MongoDB.ipynb       # AnÃ¡lisis exploratorio y ETL
â”‚   â””â”€â”€ Consultas_CRUD.ipynb        # 15 consultas CRUD complejas
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â”œâ”€â”€ start_project.py            # Script de inicio del proyecto (con barras de progreso)
â”‚   â”œâ”€â”€ setup_project.py            # Script de configuraciÃ³n inicial
â”‚   â”œâ”€â”€ progress_utils.py           # Utilidades de barras de progreso
â”‚   â””â”€â”€ common_utils.py             # Utilidades comunes para scripts
â”œâ”€â”€ ğŸ“„ README.md                    # Este archivo
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencias Python
â””â”€â”€ ğŸ“„ .gitignore                   # Archivos a ignorar
```

## ğŸ³ Iniciar el Cluster MongoDB

### OpciÃ³n 1: ConfiguraciÃ³n Inicial (Primera vez)

```bash
# Configurar el proyecto por primera vez
python scripts/setup_project.py
```

### OpciÃ³n 2: Usar el Script AutomÃ¡tico (Recomendado)

```bash
# Activar entorno conda
conda activate mongo

# Ejecutar script de inicio (con barras de progreso y colores)
python scripts/start_project.py
```

El script automÃ¡tico incluye:
- âœ… **Barras de progreso** visuales para cada paso
- âœ… **VerificaciÃ³n automÃ¡tica** de requisitos (Docker, Python packages)
- âœ… **Colores** para mejor experiencia de usuario
- âœ… **Animaciones** de progreso
- âœ… **GuÃ­a interactiva** para el usuario

### OpciÃ³n 2: Inicio Manual

```bash
# Navegar al directorio docker
cd docker

# Iniciar cluster MongoDB
docker-compose up -d

# Verificar que los contenedores estÃ©n corriendo
docker-compose ps

# Ver logs si hay problemas
docker-compose logs
```

### Verificar ReplicaciÃ³n

```bash
# Conectar al primario
docker exec -it mongo-primary mongosh --username admin --password password123

# Verificar estado del replica set
rs.status()
```

## ğŸ“Š Ejecutar AnÃ¡lisis de Datos

### 1. Iniciar Jupyter Notebook

```bash
# Activar entorno conda
conda activate mongo

# Iniciar Jupyter
jupyter notebook
```

### 2. Configurar Kernel

Al abrir los notebooks, asegÃºrate de seleccionar el kernel correcto:
- **Kernel** â†’ **Change kernel** â†’ **Python (mongo)**

Si no aparece el kernel, instÃ¡lalo:

```bash
conda activate mongo
python -m ipykernel install --user --name mongo --display-name "Python (mongo)"
```

### 3. Ejecutar Notebooks

#### Notebook EDA y ETL (`notebooks/EDA_ETL_MongoDB.ipynb`)

Este notebook realiza:
- âœ… **Descarga automÃ¡tica** del dataset Brazilian E-commerce
- âœ… **AnÃ¡lisis exploratorio** de 9 datasets CSV
- âœ… **Limpieza inteligente** basada en el EDA
- âœ… **CombinaciÃ³n de datasets** (Orders + Items + Products + Customers + Sellers + Payments + Reviews)
- âœ… **Carga a MongoDB** con verificaciÃ³n de replicaciÃ³n
- âœ… **Visualizaciones** completas

#### Notebook CRUD (`notebooks/Consultas_CRUD.ipynb`)

Este notebook incluye **15 consultas complejas**:
1. Ventas de Ãºltimos 3 meses por cliente
2. AgregaciÃ³n por producto con totales
3. AnÃ¡lisis de stock y tendencias
4. Consultas desde nodos secundarios
5. Actualizaciones condicionales
6. Eliminaciones con validaciones
7. Agregaciones complejas
8. Optimizaciones con Ã­ndices

## ğŸ¨ Utilidades de Progreso

### Usar Barras de Progreso en Notebooks

Para mejorar la experiencia visual en los notebooks, puedes importar las utilidades de progreso:

```python
# En tu notebook
from scripts.progress_utils import *

# Mostrar pasos del ETL
progress_etl_steps()

# Mostrar progreso de limpieza de datos
progress_data_cleaning(df)

# Mostrar progreso de operaciones MongoDB
progress_mongodb_operations(["Conectar", "Insertar", "Verificar"])

# Verificar replicaciÃ³n con animaciÃ³n
show_replication_status()

# Mostrar informaciÃ³n del DataFrame con progreso
show_dataframe_info_with_progress(df, "Mi Dataset")
```

### Funciones Disponibles

- `progress_etl_steps()`: Muestra los pasos del proceso ETL
- `show_dataframe_info_with_progress()`: AnÃ¡lisis de DataFrame con barra de progreso
- `progress_data_cleaning()`: Progreso de limpieza de datos
- `progress_mongodb_operations()`: Operaciones MongoDB con progreso
- `show_replication_status()`: VerificaciÃ³n de replicaciÃ³n con animaciÃ³n
- `show_dataset_download_progress()`: Progreso de descarga de dataset
- `show_csv_loading_progress()`: Carga de archivos CSV con progreso
- `show_eda_progress()`: Progreso del anÃ¡lisis exploratorio

## ğŸ”§ Comandos Ãštiles

### Docker

```bash
# Iniciar cluster
docker-compose -f docker/docker-compose.yml up -d

# Detener cluster
docker-compose -f docker/docker-compose.yml down

# Ver logs
docker-compose -f docker/docker-compose.yml logs -f

# Reiniciar servicios
docker-compose -f docker/docker-compose.yml restart
```

### MongoDB

```bash
# Conectar al primario
docker exec -it mongo-primary mongosh --username admin --password password123

# Conectar a secundario 1
docker exec -it mongo-secondary1 mongosh --username admin --password password123

# Conectar a secundario 2
docker exec -it mongo-secondary2 mongosh --username admin --password password123
```

### Python/Anaconda

```bash
# ConfiguraciÃ³n inicial (primera vez)
python scripts/setup_project.py

# Activar entorno
conda activate mongo

# Verificar librerÃ­as
python -c "import pandas, numpy, matplotlib, seaborn, pymongo, kagglehub; print('âœ… Todas las librerÃ­as funcionan')"

# Instalar kernel Jupyter
python -m ipykernel install --user --name mongo --display-name "Python (mongo)"
```

## ğŸ“ˆ CaracterÃ­sticas del Dataset

### Datasets Originales (9 archivos CSV):
- **olist_customers_dataset**: 99,441 clientes
- **olist_geolocation_dataset**: 1,000,163 ubicaciones
- **olist_orders_dataset**: 99,441 pedidos
- **olist_order_items_dataset**: 112,650 items
- **olist_order_payments_dataset**: 103,886 pagos
- **olist_order_reviews_dataset**: 99,224 reseÃ±as
- **olist_products_dataset**: 32,951 productos
- **olist_sellers_dataset**: 3,095 vendedores
- **product_category_name_translation**: 71 categorÃ­as

### Dataset Final Procesado:
- **Registros**: ~100,000 ventas completas
- **Columnas**: 20+ campos relevantes
- **PerÃ­odo**: 2017-2018
- **GeografÃ­a**: Brasil completo

## ğŸ¯ Resultados Esperados

### EDA y ETL:
- âœ… Dataset descargado automÃ¡ticamente
- âœ… AnÃ¡lisis exploratorio completo
- âœ… Limpieza inteligente de datos
- âœ… Dataset unificado cargado en MongoDB
- âœ… VerificaciÃ³n de replicaciÃ³n exitosa

### Consultas CRUD:
- âœ… 15 consultas complejas ejecutadas
- âœ… Operaciones de agregaciÃ³n optimizadas
- âœ… Lecturas desde nodos secundarios
- âœ… Actualizaciones y eliminaciones seguras
- âœ… AnÃ¡lisis de rendimiento con Ã­ndices

## ğŸ› SoluciÃ³n de Problemas

### Error: "ModuleNotFoundError: No module named 'seaborn'"
```bash
conda activate mongo
pip install seaborn
```

### Error: "Connection refused" en MongoDB
```bash
# Verificar que Docker estÃ© corriendo
docker ps

# Reiniciar cluster
docker-compose -f docker/docker-compose.yml down
docker-compose -f docker/docker-compose.yml up -d
```

### Error: Kernel no encontrado en Jupyter
```bash
conda activate mongo
python -m ipykernel install --user --name mongo --display-name "Python (mongo)"
```

### Error: Dataset no se descarga
```bash
# Verificar kagglehub
pip install kagglehub

# O usar datos de ejemplo (el notebook tiene fallback)
```

## ğŸ“ Notas Importantes

1. **Entorno Conda**: Siempre activa el entorno `mongo` antes de trabajar
2. **Puertos**: MongoDB usa puertos 27017, 27018, 27019
3. **Credenciales**: admin/password123 (configurables en docker-compose.yml)
4. **Datos**: El dataset se descarga automÃ¡ticamente (~100MB)
5. **ReplicaciÃ³n**: Espera 2-3 segundos para que se repliquen los datos

## ğŸ‘¥ ContribuciÃ³n

Para contribuir al proyecto:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ¤ Autores

- **Tu Nombre** - *Trabajo inicial* - [TuUsuario](https://github.com/TuUsuario)

## ğŸ™ Agradecimientos

- Dataset: [Brazilian E-commerce by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
- MongoDB para la documentaciÃ³n de replicaciÃ³n
- Docker para la containerizaciÃ³n

---

**Â¡Disfruta explorando los datos de e-commerce brasileÃ±o con MongoDB! ğŸš€** 